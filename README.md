# Goal

Binary and 4 bit-width quantization-aware-training (QAT) a custom neural-network model. Output of the process ONNX file is used as input file of FINN compiler.


# Brevitas

Brevitas is a PyTorch library for neural network quantization, with support for both post-training quantization (PTQ) and quantization-aware training (QAT).

# Software Version
Brevitas: 0.10.2 (tag:TBD)

Ubuntu: 20.04

Python: 3.10.12 (>= 3.8) 

Torch: 2.1.0 (Brevitas 0.10.0 supports up to Torch 2.1.0 and higher than 1.9.1)

CUDA: 12.2


# Source

Xilinx:  

https://github.com/Xilinx/brevitas  
https://xilinx.github.io/brevitas/getting_started

# Directory

Directories are followed respectively and each step has variants. 

1-Basic (W1A2, W2A2) 

2-Advance 

3-Custom 

# Big Picture Brevitas-FINN-FPGA

![General Diagram2 drawio](https://github.com/Ba1tu3han/Brevitas_Thesis/assets/29502318/528d0112-5921-4df7-b393-750e1c24635e)






